{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import mediapipe\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_x = 500\n",
    "dim_y = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_labels = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']\n",
    "count_labels = len(y_labels)\n",
    "\n",
    "n_cat = 1000\n",
    "count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'L'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_labels[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "fontScale = 0.7\n",
    "color = (0, 0, 255)\n",
    "thickness = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Folders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "path = r'datasets'\n",
    "os.mkdir(path)\n",
    "for label in y_labels:\n",
    "    dir_path = os.path.join(path, label)\n",
    "    os.mkdir(dir_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Status:\n",
    "1. collecting\n",
    "2. paused"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-2f42657eeedf>:39: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_data = np.array(points)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collecting\n",
      "collecting\n",
      "collecting\n",
      "collecting\n",
      "collecting\n",
      "collecting\n",
      "collecting\n",
      "collecting\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(2)\n",
    "sample = cv2.imread(\"ASL_Alphabet.jpg\")\n",
    "cv2.imshow(\"sample\", sample)\n",
    "\n",
    "status = \"idle\"\n",
    "count = 0\n",
    "curr_cat = int(11)\n",
    "max_samples = 3000\n",
    "\n",
    "frameHeight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "frameWidth = frameHeight\n",
    "\n",
    "drawingModule = mediapipe.solutions.drawing_utils\n",
    "handsModule = mediapipe.solutions.hands\n",
    "\n",
    "path = r\"datasets\"\n",
    "\n",
    "with handsModule.Hands(static_image_mode=False, min_detection_confidence=0.7, min_tracking_confidence=0.7, max_num_hands=2) as hands:\n",
    "    while (curr_cat < len(y_labels)):\n",
    "        \n",
    "        dir_path = os.path.join(path, y_labels[curr_cat])\n",
    "        \n",
    "        ret, frame = cap.read()\n",
    "        frame = frame[0:frameHeight, 0:frameHeight]\n",
    "        raw = frame.copy()\n",
    "\n",
    "        results = hands.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "        img = cv2.putText(frame, 'Sample Data Collector', (30,30), font, 1, (255,0,0), 1, cv2.LINE_AA)\n",
    "        points = []\n",
    "        if results.multi_hand_landmarks != None:\n",
    "            for handLandmarks in results.multi_hand_landmarks:\n",
    "                for point in handsModule.HandLandmark:\n",
    "                    normalizedLandmark = handLandmarks.landmark[point]\n",
    "                    pixelCoordinatesLandmark = drawingModule._normalized_to_pixel_coordinates(normalizedLandmark.x, normalizedLandmark.y, frameWidth, frameHeight)\n",
    "                    #print(pixelCoordinatesLandmark)\n",
    "                    cv2.circle(frame, pixelCoordinatesLandmark, 4, (0, 255, 0), -1)\n",
    "                    points.append(pixelCoordinatesLandmark)\n",
    "            if(len(points) == 21):\n",
    "                x_data = np.array(points)\n",
    "                img = cv2.putText(frame, 'Hand Detected', (30,60), font, fontScale, color, thickness, cv2.LINE_AA)\n",
    "                img = cv2.putText(frame, 'Category : '+y_labels[curr_cat], (30,90), font, fontScale, color, thickness, cv2.LINE_AA)\n",
    "                img = cv2.putText(frame, 'Data point : '+str(count), (30,120), font, fontScale, color, thickness, cv2.LINE_AA)\n",
    "                \n",
    "                \n",
    "                if(status == 'collecting' and count < max_samples):\n",
    "                    count += 1\n",
    "                    img_path = os.path.join(dir_path, str(count)+\".jpg\")\n",
    "                    cv2.imwrite(img_path, raw) #save img\n",
    "                    \n",
    "                elif(count == max_samples):\n",
    "                    count = 0\n",
    "                    status = \"idle\"\n",
    "                    curr_cat += 1\n",
    "        \n",
    "            elif(len(points) == 42):\n",
    "                img = cv2.putText(frame, 'Please use only one hand', (30,60), font, fontScale, color, thickness, cv2.LINE_AA)\n",
    "        else:\n",
    "                img = cv2.putText(frame, 'Hand not detected', (30,60), font, fontScale, color, thickness, cv2.LINE_AA)\n",
    "        cv2.imshow('Test hand', img)\n",
    "        \n",
    "        key = cv2.waitKey(1)\n",
    "        if(key == 27 or key == ord('q')):\n",
    "            break\n",
    "        elif(key == ord('s') or key == ord('S')):\n",
    "            cv2.waitKey(100)\n",
    "            status = 'collecting'\n",
    "            print(status)\n",
    "        elif(key == ord('p') or key == ord('P')):\n",
    "            status = 'paused'\n",
    "            print(status)\n",
    "        elif(key == ord('r') or key == ord('R')):\n",
    "            status = \"restart\"\n",
    "            print(\"restart??\")\n",
    "            count = 0\n",
    "            status = \"idle\"\n",
    "            print(status)\n",
    "            #if in middle of acquizitaion, delete and retake, else delete old record\n",
    "            #do somethinf\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S :: Start data collection in 100 Seconds\n",
    "# P :: Pause data collection\n",
    "# R :: Restart Data Collection\n",
    "# Q :: Quit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
